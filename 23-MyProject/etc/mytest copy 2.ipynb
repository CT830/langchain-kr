{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API 키를 환경변수로 관리하기 위한 설정 파일\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API 키 정보 로드\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain-teddynote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LangSmith 추적을 설정합니다. https://smith.langchain.com\n",
    "# !pip install langchain-teddynote\n",
    "from langchain_teddynote import logging\n",
    "\n",
    "# 프로젝트 이름을 입력합니다.\n",
    "logging.langsmith(\"CH99-MyTest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "from chromadb.config import Settings\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 현재 디렉토리에 DB 저장 경로 설정\n",
    "current_dir = os.getcwd()\n",
    "db_path = os.path.join(current_dir, \"my_db.db\")\n",
    "\n",
    "# ChromaDB 클라이언트 초기화 (영구 저장소 설정)\n",
    "client = chromadb.PersistentClient(\n",
    "    path=db_path, settings=Settings(allow_reset=True, is_persistent=True)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding 함수 설정\n",
    "embedding_function = embedding_functions.SentenceTransformerEmbeddingFunction(\n",
    "    model_name='all-MiniLM-L6-v2'\n",
    ")\n",
    "\n",
    "def reset_collection(client, collection_name):\n",
    "    try:\n",
    "        # 기존 컬렉션 존재 여부 확인\n",
    "        existing_collections = client.list_collections()\n",
    "        collection_exists = any(col.name == collection_name for col in existing_collections)\n",
    "        \n",
    "        if collection_exists:\n",
    "            print(f\"기존 컬렉션 '{collection_name}'을 삭제합니다.\")\n",
    "            client.delete_collection(collection_name)\n",
    "            print(f\"컬렉션 '{collection_name}'이 삭제되었습니다.\")\n",
    "        \n",
    "        # 새로운 컬렉션 생성\n",
    "        print(f\"새로운 컬렉션 '{collection_name}'을 생성합니다.\")\n",
    "        collection = client.create_collection(\n",
    "            name=collection_name,\n",
    "            embedding_function=embedding_function\n",
    "        )\n",
    "        \n",
    "        print(f\"컬렉션 '{collection_name}'이 성공적으로 초기화되었습니다.\")\n",
    "        return collection\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"컬렉션 초기화 중 오류 발생: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "# 컬렉션 초기화 실행\n",
    "collection = reset_collection(client, \"my_collection\")\n",
    "\n",
    "# 컬렉션 정보 확인\n",
    "print(\"\\n=== 초기화된 컬렉션 정보 ===\")\n",
    "print(f\"컬렉션 이름: {collection.name}\")\n",
    "print(f\"컬렉션 크기: {collection.count()} 문서\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV 파일 읽기\n",
    "df = pd.read_csv(\"./data/gong.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentence Transformer 임베딩 함수 설정\n",
    "embedding_function = embedding_functions.SentenceTransformerEmbeddingFunction(\n",
    "    model_name=\"all-MiniLM-L6-v2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 컬렉션 생성 (이미 존재하는 경우 가져오기)\n",
    "try:\n",
    "    collection = client.get_or_create_collection(\n",
    "        name=\"my_collection\", embedding_function=embedding_function\n",
    "    )\n",
    "except ValueError:\n",
    "    # 이미 존재하는 경우 기존 컬렉션 가져오기\n",
    "    collection = client.get_collection(\n",
    "        name=\"my_collection\", embedding_function=embedding_function\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if collection.name == \"my_collection\":\n",
    "    collection_exist = True\n",
    "    print(\"\\n=== 컬렉션 정보 ===\")\n",
    "    print(f\"컬렉션 이름: {collection.name}\")\n",
    "    print(f\"컬렉션 크기: {collection.count()} 문서\")\n",
    "else:\n",
    "    collection_exist = False\n",
    "    print(\"collection does not exist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 행을 문자열로 변환하는 함수\n",
    "def row_to_string(row):\n",
    "    return \" \".join([f\"{col}: {val}\" for col, val in row.items()])\n",
    "\n",
    "\n",
    "# 배치 크기 설정\n",
    "BATCH_SIZE = 100\n",
    "\n",
    "if collection_exist == False:\n",
    "    # 전체 데이터 처리를 위한 반복 횟수 계산\n",
    "    num_batches = len(df) // BATCH_SIZE + (1 if len(df) % BATCH_SIZE != 0 else 0)\n",
    "\n",
    "    # 배치 처리로 데이터 저장\n",
    "    for i in tqdm(range(num_batches)):\n",
    "        start_idx = i * BATCH_SIZE\n",
    "        end_idx = min((i + 1) * BATCH_SIZE, len(df))\n",
    "\n",
    "        batch_df = df.iloc[start_idx:end_idx]\n",
    "\n",
    "        documents = []\n",
    "        ids = []\n",
    "\n",
    "        for idx, row in batch_df.iterrows():\n",
    "            # 각 행을 문자열로 변환\n",
    "            doc_string = row_to_string(row)\n",
    "            documents.append(doc_string)\n",
    "            ids.append(str(idx))\n",
    "\n",
    "        # ChromaDB에 배치 추가\n",
    "        collection.add(documents=documents, ids=ids)\n",
    "\n",
    "    print(f\"총 {len(df)}개의 행이 성공적으로 저장되었습니다.\")\n",
    "    print(f\"데이터베이스가 다음 경로에 저장되었습니다: {db_path}\")\n",
    "else:\n",
    "    print(f\"컬렉션 이름: {collection.name} 을 불러왔습니다.\")\n",
    "    print(f\"컬렉션 크기: {collection.count()} 문서\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 첫 번째 document 가져오기\n",
    "result = collection.get(\n",
    "    ids=[\"0\"],  # 첫 번째 행의 ID\n",
    "    include=[\"documents\", \"embeddings\"],  # documents와 embeddings 모두 포함\n",
    ")\n",
    "\n",
    "print(\"Document 내용:\")\n",
    "print(result[\"documents\"][0])  # 첫 번째 document의 텍스트 내용\n",
    "\n",
    "print(\"\\nEmbedding 벡터 (처음 10개 값):\")\n",
    "print(result[\"embeddings\"][0][:10])  # 임베딩 벡터의 처음 10개 값만 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "import os\n",
    "\n",
    "# ChromaDB 클라이언트 연결\n",
    "client = chromadb.PersistentClient(path=\"my_db.db\")\n",
    "\n",
    "# Embedding 함수 설정\n",
    "embedding_function = embedding_functions.SentenceTransformerEmbeddingFunction(\n",
    "    model_name=\"all-MiniLM-L6-v2\"\n",
    ")\n",
    "\n",
    "# 컬렉션 가져오기\n",
    "collection = client.get_collection(\n",
    "    name=\"my_collection\", embedding_function=embedding_function\n",
    ")\n",
    "\n",
    "# 쿼리 실행\n",
    "query = \"예비창업패키지 지원사업 알려줘\"\n",
    "results = collection.query(query_texts=[query], n_results=3)  # 상위 3개 결과 가져오기\n",
    "# results = collection.query(\n",
    "#     query_texts=[query],\n",
    "#     n_results=3,\n",
    "#     where_document={\n",
    "#         \"$and\": [\n",
    "#             {\"$contains\": \"col6\"}, # 지역\n",
    "#             {\"$contains\": \"col7\"}, # 지원 대상 ( 대학생, 일반인, 대학 등 )\n",
    "#            # {\"$contains\": \"col8\"}  # 지원 연령 ( 만 20세 이상 등 )\n",
    "#         ]\n",
    "#     }\n",
    "# )\n",
    "\n",
    "# 검색 결과 출력\n",
    "print(\"=== 검색된 문서 ===\")\n",
    "for i, doc in enumerate(results[\"documents\"][0]):\n",
    "    print(f\"\\nDocument {i+1}:\")\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI를 사용한 답변 생성\n",
    "# 객체 생성\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0.1,  # 창의성 (0.0 ~ 2.0)\n",
    "    model_name=\"gpt-4o\",  # 모델명\n",
    ")\n",
    "# client = OpenAI(\n",
    "#     api_key=\"<OpenAI API Key>\"\n",
    "# )  # OpenAI API 키 입력\n",
    "\n",
    "# 프롬프트 구성\n",
    "prompt = f\"\"\"다음은 예비창업자가 지원할 수 있는 지원사업에 대한 검색 결과입니다. \n",
    "이를 바탕으로 예비창업자가 지원할 수 있는 주요 지원사업들을 간단명료하게 요약해서 설명해주세요:\n",
    "\n",
    "{results['documents'][0]}\n",
    "\"\"\"\n",
    "\n",
    "# ChatGPT API 호출\n",
    "# response = client.chat.completions.create(\n",
    "#     model=\"gpt-4o\",\n",
    "#     messages=[\n",
    "#         {\n",
    "#             \"role\": \"system\",\n",
    "#             \"content\": \"You are a helpful assistant that explains startup support programs in Korean.\",\n",
    "#         },\n",
    "#         {\"role\": \"user\", \"content\": prompt},\n",
    "#     ],\n",
    "#     temperature=0,\n",
    "#     max_tokens=1000,\n",
    "# )\n",
    "response = llm.invoke(prompt)\n",
    "\n",
    "print(\"\\n=== AI 답변 ===\")\n",
    "print(response.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-kr-uRT90lmq-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
