{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API 키를 환경변수로 관리하기 위한 설정 파일\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API 키 정보 로드\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LangSmith 추적을 설정합니다. https://smith.langchain.com\n",
    "# !pip install langchain-teddynote\n",
    "from langchain_teddynote import logging\n",
    "\n",
    "# 프로젝트 이름을 입력합니다.\n",
    "logging.langsmith(\"CH99-MyTest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "from chromadb.config import Settings\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "# 현재 디렉토리에 DB 저장 경로 설정\n",
    "current_dir = os.getcwd()\n",
    "db_path = os.path.join(current_dir, \"my_db.db\")\n",
    "\n",
    "# ChromaDB 클라이언트 초기화 (영구 저장소 설정)\n",
    "client = chromadb.PersistentClient(\n",
    "    path=db_path, settings=Settings(allow_reset=True, is_persistent=True)\n",
    ")\n",
    "\n",
    "# CSV 파일 읽기\n",
    "df = pd.read_csv(\"./data/gong.csv\")\n",
    "\n",
    "# Sentence Transformer 임베딩 함수 설정\n",
    "embedding_function = embedding_functions.SentenceTransformerEmbeddingFunction(\n",
    "    model_name=\"all-MiniLM-L6-v2\"\n",
    ")\n",
    "\n",
    "# 컬렉션 생성 (이미 존재하는 경우 가져오기)\n",
    "try:\n",
    "    collection = client.create_collection(\n",
    "        name=\"my_collection\", embedding_function=embedding_function\n",
    "    )\n",
    "except ValueError:\n",
    "    # 이미 존재하는 경우 기존 컬렉션 가져오기\n",
    "    collection = client.get_collection(\n",
    "        name=\"my_collection\", embedding_function=embedding_function\n",
    "    )\n",
    "\n",
    "\n",
    "# 각 행을 문자열로 변환하는 함수\n",
    "def row_to_string(row):\n",
    "    return \" \".join([f\"{col}: {val}\" for col, val in row.items()])\n",
    "\n",
    "\n",
    "# 배치 크기 설정\n",
    "BATCH_SIZE = 100\n",
    "\n",
    "# 전체 데이터 처리를 위한 반복 횟수 계산\n",
    "num_batches = len(df) // BATCH_SIZE + (1 if len(df) % BATCH_SIZE != 0 else 0)\n",
    "\n",
    "# 배치 처리로 데이터 저장\n",
    "for i in tqdm(range(num_batches)):\n",
    "    start_idx = i * BATCH_SIZE\n",
    "    end_idx = min((i + 1) * BATCH_SIZE, len(df))\n",
    "\n",
    "    batch_df = df.iloc[start_idx:end_idx]\n",
    "\n",
    "    documents = []\n",
    "    ids = []\n",
    "\n",
    "    for idx, row in batch_df.iterrows():\n",
    "        # 각 행을 문자열로 변환\n",
    "        doc_string = row_to_string(row)\n",
    "        documents.append(doc_string)\n",
    "        ids.append(str(idx))\n",
    "\n",
    "    # ChromaDB에 배치 추가\n",
    "    collection.add(documents=documents, ids=ids)\n",
    "\n",
    "print(f\"총 {len(df)}개의 행이 성공적으로 저장되었습니다.\")\n",
    "print(f\"데이터베이스가 다음 경로에 저장되었습니다: {db_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 첫 번째 document 가져오기\n",
    "result = collection.get(\n",
    "    ids=[\"0\"],  # 첫 번째 행의 ID\n",
    "    include=[\"documents\", \"embeddings\"],  # documents와 embeddings 모두 포함\n",
    ")\n",
    "\n",
    "print(\"Document 내용:\")\n",
    "print(result[\"documents\"][0])  # 첫 번째 document의 텍스트 내용\n",
    "\n",
    "print(\"\\nEmbedding 벡터 (처음 10개 값):\")\n",
    "print(result[\"embeddings\"][0][:10])  # 임베딩 벡터의 처음 10개 값만 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "import os\n",
    "\n",
    "# ChromaDB 클라이언트 연결\n",
    "client = chromadb.PersistentClient(path=\"my_db.db\")\n",
    "\n",
    "# Embedding 함수 설정\n",
    "embedding_function = embedding_functions.SentenceTransformerEmbeddingFunction(\n",
    "    model_name=\"all-MiniLM-L6-v2\"\n",
    ")\n",
    "\n",
    "# 컬렉션 가져오기\n",
    "collection = client.get_collection(\n",
    "    name=\"my_collection\", embedding_function=embedding_function\n",
    ")\n",
    "\n",
    "# 쿼리 실행\n",
    "query = \"예비창업자가 지원할 수 있는 지원사업은\"\n",
    "results = collection.query(query_texts=[query], n_results=3)  # 상위 3개 결과 가져오기\n",
    "\n",
    "# 검색 결과 출력\n",
    "print(\"=== 검색된 문서 ===\")\n",
    "for i, doc in enumerate(results[\"documents\"][0]):\n",
    "    print(f\"\\nDocument {i+1}:\")\n",
    "    print(doc)\n",
    "\n",
    "# OpenAI를 사용한 답변 생성\n",
    "client = OpenAI()\n",
    "# OpenAI API 키 입력\n",
    "\n",
    "# 프롬프트 구성\n",
    "prompt = f\"\"\"다음은 예비창업자가 지원할 수 있는 지원사업에 대한 검색 결과입니다. \n",
    "이를 바탕으로 예비창업자가 지원할 수 있는 주요 지원사업들을 간단명료하게 요약해서 설명해주세요:\n",
    "\n",
    "{results['documents'][0]}\n",
    "\"\"\"\n",
    "\n",
    "# ChatGPT API 호출\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful assistant that explains startup support programs in Korean.\",\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "    ],\n",
    "    temperature=0.7,\n",
    "    max_tokens=1000,\n",
    ")\n",
    "\n",
    "print(\"\\n=== AI 답변 ===\")\n",
    "print(response.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-kr-uRT90lmq-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
